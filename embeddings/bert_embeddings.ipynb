{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/zRjkDZYBbyODu/JFSJ+8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/littleadam/AI_ML/blob/main/embeddings/bert_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naF1IGMiAIHB",
        "outputId": "2d4cf448-1eb6-4dde-886c-fababe7eda9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding: tensor([[-4.4204e-01, -4.7610e-01,  1.4443e-01, -8.2655e-02, -2.8969e-02,\n",
            "         -2.5848e-01,  1.0724e-01, -2.0515e-01, -3.4652e-02,  5.7546e-02,\n",
            "          5.0493e-02,  6.6971e-02, -1.7401e-01, -1.1479e-02,  6.0353e-02,\n",
            "          2.5265e-01, -1.0689e-01,  1.5538e-01,  7.6280e-02, -4.1466e-01,\n",
            "          1.7250e-01,  4.0373e-02, -2.2241e-01,  1.0362e-01,  2.9920e-01,\n",
            "         -2.1684e-02,  1.3001e-01, -1.0716e-01, -2.4391e-01,  6.9407e-02,\n",
            "         -2.1875e-01,  4.3056e-01,  9.0748e-02, -3.4478e-01, -1.4620e-01,\n",
            "          3.2258e-01,  7.2712e-02, -8.8781e-03, -2.1443e-03,  2.4236e-01,\n",
            "         -2.1845e-01, -3.9874e-01, -1.7328e-02,  1.6181e-01, -1.9227e-01,\n",
            "         -4.2296e-01, -3.2074e-02, -8.1401e-02,  2.6775e-01, -5.6682e-01,\n",
            "         -1.3416e+00,  5.6351e-01, -2.9184e-01,  3.1193e-01,  9.4185e-02,\n",
            "          2.8669e-01,  3.6905e-01, -7.7056e-01,  4.1555e-01,  4.7482e-02,\n",
            "          8.6175e-03, -4.5327e-04, -1.4721e-01, -6.9306e-01,  4.1963e-01,\n",
            "          2.2546e-01, -3.5138e-01,  2.3118e-01, -8.4083e-01,  1.2591e-02,\n",
            "         -3.3849e-01, -4.2830e-02, -1.8282e-01,  1.1028e-01, -4.5449e-01,\n",
            "          7.6367e-02, -9.4033e-02,  2.8139e-01, -2.1563e-01,  2.7014e-02,\n",
            "         -1.5865e-01,  5.7349e-01,  3.7497e-01,  2.0757e-01,  6.4298e-01,\n",
            "          1.5160e-01,  7.7349e-02,  5.5155e-01, -2.2914e-01,  4.0037e-01,\n",
            "          2.7058e-02, -3.0179e-01, -3.5644e-01,  2.4271e-01,  6.5207e-01,\n",
            "          3.1450e-01, -3.6331e-01, -1.7947e-01,  8.2876e-02,  4.1431e-01,\n",
            "          3.8189e-01, -7.8999e-01,  1.3802e-01, -1.4188e-01, -2.7541e-01,\n",
            "         -3.3252e-01, -2.4879e-01,  7.4699e-02,  9.4841e-02,  1.4933e-01,\n",
            "          7.4390e-02,  7.3264e-02,  1.5215e-01, -4.5402e-01,  3.1626e-02,\n",
            "          1.4731e-01,  8.5200e-02,  1.4938e-01, -6.4337e-02, -1.9711e-01,\n",
            "          1.9298e-01,  6.3651e-01,  2.0176e-01,  1.0876e+00, -9.9129e-02,\n",
            "          2.2809e-01,  1.7665e-01,  4.8761e-01,  2.5853e-01, -1.4928e-01,\n",
            "          2.7352e-01,  3.1939e-01,  7.4004e-01, -3.8522e-01, -4.5344e-01,\n",
            "          2.2685e-01, -3.1516e-01, -5.4554e-02, -6.3257e-01,  1.7963e-01,\n",
            "         -1.6980e-01, -1.2054e-01,  5.4301e-01,  5.2990e-02,  5.4239e-01,\n",
            "          3.4856e-01, -6.9947e-02, -4.6405e-01,  4.0371e-02,  1.9874e-01,\n",
            "          1.9453e-01,  3.3227e-01, -5.2585e-01, -3.2251e-01, -3.1038e-01,\n",
            "          2.6658e-01, -7.1088e-02,  1.3386e-01,  2.2205e-01,  1.5871e-01,\n",
            "          1.4148e-01, -1.6995e-03, -2.8591e-01, -3.2652e-01, -4.5266e-02,\n",
            "         -7.0053e-04,  2.3179e-01,  3.6845e-01,  3.2962e-01,  2.1292e-01,\n",
            "         -3.3479e-01, -1.6205e-01,  1.2771e-01, -7.8693e-02, -2.5388e-01,\n",
            "         -1.5653e-02,  3.4209e-01, -2.1089e-01,  1.8445e-01,  4.2746e-02,\n",
            "         -1.5428e+00,  2.2506e-01,  4.2369e-01, -4.9962e-01,  2.6017e-01,\n",
            "          1.7866e-01,  4.4678e-01, -5.3073e-01, -4.3045e-01, -2.4524e-01,\n",
            "         -4.3227e-01, -1.1522e-01, -3.3554e-01, -3.9502e-01,  8.1297e-01,\n",
            "         -1.3508e-01, -2.3457e-01, -1.3411e-04, -2.3755e-01, -2.0001e-01,\n",
            "          3.9023e-02, -1.7257e-02, -3.8660e-02, -7.3983e-02, -4.9565e-01,\n",
            "         -1.8386e-01, -2.5159e-01, -2.9203e-01, -7.2594e-01,  1.9062e-01,\n",
            "         -4.4016e-01,  3.4557e-01,  2.1552e-01, -2.3832e-02,  4.4919e-01,\n",
            "         -8.0452e-02,  1.9047e-01,  4.0038e-03,  1.3058e-01,  4.7036e-03,\n",
            "          5.9461e-01, -4.3770e-01, -5.5662e-01,  4.8247e-01, -1.6656e-01,\n",
            "          8.1866e-01,  7.2130e-01, -1.1733e-02,  6.9834e-01,  4.0255e-01,\n",
            "          1.1964e-01, -3.8000e-01,  1.6306e-01, -1.6461e-01, -4.9413e-01,\n",
            "          9.3524e-02,  5.2648e-02, -1.8992e-01,  8.1597e-02,  1.1649e-01,\n",
            "         -2.7083e-01,  6.1967e-01,  4.8298e-01, -2.6249e-01,  2.8314e-01,\n",
            "         -7.3265e-01, -1.5738e-01,  3.3849e-02, -1.3326e-02, -6.6345e-01,\n",
            "         -2.7940e-01,  7.9593e-02,  1.1826e-01, -5.3520e-01,  9.0787e-02,\n",
            "          2.8191e-01, -1.7014e-01, -2.3443e-02, -2.5202e-01,  6.3590e-01,\n",
            "          1.7958e-01,  9.9046e-02, -1.8508e-01,  5.9259e-02, -7.6045e-02,\n",
            "         -6.5859e-01, -8.2967e-02,  1.9711e-01,  7.1611e-01,  4.3244e-01,\n",
            "         -1.8724e-01, -8.3794e-01, -1.3115e-01,  5.8176e-02, -2.0528e-01,\n",
            "         -7.4917e-01, -3.0309e-01,  7.5903e-02, -2.9775e-01, -2.4924e-02,\n",
            "          3.8357e-01,  6.0378e-01, -1.0662e-01,  1.0895e-01, -3.0396e-01,\n",
            "          1.4940e-01, -9.4514e-02, -3.1846e-02,  3.6457e-02, -5.9405e-01,\n",
            "         -6.4414e-03,  1.3261e-01, -4.2321e-01, -2.0891e-01,  1.0079e-01,\n",
            "          3.8444e-01,  3.5650e-01,  1.0247e-01, -1.0243e-01, -2.9131e-01,\n",
            "         -2.8940e-01, -5.0255e-01, -2.6725e-01,  1.6949e-01, -7.9942e-03,\n",
            "          3.7542e-01, -2.6281e-01, -1.5158e-01, -3.0385e+00, -1.7554e-01,\n",
            "         -1.8607e-01,  3.0337e-01,  2.5848e-01, -1.2746e-01, -5.5266e-02,\n",
            "         -1.8947e-01, -3.2559e-01,  6.5408e-02, -2.9401e-01, -5.2335e-01,\n",
            "         -5.2677e-01,  6.4157e-01,  2.4642e-02,  1.7700e-01, -7.4265e-02,\n",
            "         -1.1505e-01,  3.0305e-01, -3.1722e-01,  3.6138e-02, -4.1789e-01,\n",
            "         -3.4497e-01, -2.4637e-01, -1.8204e-04,  3.3790e-01, -2.1913e-01,\n",
            "          2.9860e-01, -3.8935e-01, -4.1060e-01, -2.3469e-01, -4.6138e-01,\n",
            "          4.1825e-01, -8.7218e-02, -1.2196e-01,  5.0161e-02,  4.7069e-02,\n",
            "          1.6364e-02,  1.5051e-01, -6.8490e-01, -1.0035e-01,  3.1344e-01,\n",
            "          3.6539e-01,  3.2626e-02,  7.1010e-01, -4.2339e-01, -1.5883e-01,\n",
            "         -3.4101e-01,  2.6128e-01, -1.4210e-01, -2.2078e-01, -1.7892e-01,\n",
            "         -1.6936e-01, -2.2303e-01, -1.5243e-01, -6.8635e-01,  3.4984e-01,\n",
            "          3.3256e-01, -1.8555e-01,  2.9901e-01,  6.6476e-01, -2.6241e-01,\n",
            "          2.8733e-02, -5.0579e-01, -2.6993e-01,  6.8654e-02, -4.9419e-01,\n",
            "         -4.0451e-01, -3.7937e-01, -1.8514e-01, -3.4042e-01,  2.2751e-02,\n",
            "         -3.7970e-01, -1.1592e+00,  5.7714e-02, -7.9712e-01,  1.4792e-01,\n",
            "         -8.4941e-02,  3.4173e-02, -7.2382e-02, -4.0829e-01, -8.9485e-01,\n",
            "          1.7434e-01, -1.7522e-01,  8.4382e-02, -1.4652e-01, -3.2322e-01,\n",
            "         -2.5914e-02, -1.3809e-01, -1.8075e-01, -1.1059e-02,  3.7220e-01,\n",
            "          3.8259e-01,  4.0507e-01, -1.4519e-03,  1.1411e-01,  3.7926e-01,\n",
            "         -3.6686e-01,  4.1990e-01,  1.3136e-01,  7.7974e-02, -1.3428e-01,\n",
            "          2.0713e-01,  5.2957e-02, -1.8184e-01,  5.0938e-01, -5.0174e-01,\n",
            "          1.8626e-01,  5.3916e-01,  2.8767e-01,  8.1949e-03, -1.2188e-01,\n",
            "          4.6055e-01, -5.2634e-01, -7.4907e-02,  6.3773e-01, -1.0303e-01,\n",
            "          8.8482e-01,  3.8713e-01, -3.3620e-03, -3.0203e-02,  7.7266e-01,\n",
            "         -1.1532e-01, -2.2531e-01, -1.0949e-01, -5.3516e-02,  2.6712e-02,\n",
            "         -1.1883e-01, -1.3879e-01, -3.8779e-01, -9.0968e-04, -7.8704e-02,\n",
            "         -2.3661e-02,  3.2803e-01,  3.0129e-01, -3.8159e-01, -1.8866e-01,\n",
            "          5.0835e-01,  3.7428e-01, -1.9863e-01,  4.0459e-01,  6.6775e-01,\n",
            "         -6.5415e-02, -2.5919e-01, -9.2068e-02,  4.3599e-01,  4.7895e-02,\n",
            "          2.2113e-01, -1.2576e-01, -2.5807e-02, -1.5571e-01, -1.5473e-01,\n",
            "          3.4393e-02, -9.1509e-02,  1.3710e-01, -2.0599e-01,  3.6261e-01,\n",
            "         -3.1046e-01,  1.1905e-01, -5.5993e-01,  2.7243e-01,  5.1575e-01,\n",
            "         -8.7197e-02,  1.8742e-01, -2.2068e-01,  3.1575e-02, -1.4231e-01,\n",
            "          7.6402e-02,  6.7372e-02,  4.5121e-01, -3.2077e-01, -3.5434e-01,\n",
            "          3.8521e-01, -1.2154e-01, -1.1757e-02,  3.2941e-01,  3.8454e-01,\n",
            "         -1.7005e-01, -5.0740e-02,  5.6365e-01,  1.9544e-01, -9.3416e-02,\n",
            "          7.4211e-02,  8.0536e-02,  1.1515e-01,  2.6555e-02,  1.5991e-01,\n",
            "          3.6436e-01, -2.2491e-01, -7.9016e-04, -5.3254e-01,  3.0102e-01,\n",
            "         -8.3726e-02, -9.9051e-02, -5.8281e-01, -3.0961e-01,  3.7579e-01,\n",
            "         -8.8493e-03,  3.8826e-01, -4.1260e-01,  2.0666e-01,  2.1556e-01,\n",
            "         -1.1956e-01,  7.6194e-03,  5.9555e-02, -4.3417e-01,  6.9085e-02,\n",
            "          1.6332e-01, -1.7525e-01, -1.8119e-01, -4.3746e-01, -1.2789e-02,\n",
            "         -1.8176e-01, -7.7670e-01,  5.1072e-01,  1.4507e-01,  6.7406e-01,\n",
            "         -2.7836e-01, -6.4647e-01, -1.1271e-01, -6.2376e-01, -1.3188e-01,\n",
            "          2.8649e-01,  3.1767e-01, -6.2949e-01, -2.4014e-01, -2.1621e-01,\n",
            "         -3.3772e-01, -5.0181e-01, -7.1117e-02,  5.3308e-02, -6.9916e-01,\n",
            "          2.0271e-01,  1.9283e-01, -1.7978e-01, -2.6954e-01, -5.9844e-01,\n",
            "         -2.5527e-02, -4.7815e-02, -4.2302e-01, -3.1671e-01,  3.2704e-01,\n",
            "         -1.1953e-01, -2.0882e-01,  3.8697e-01, -3.1134e-01, -1.8074e-02,\n",
            "          2.8081e-01, -3.9423e-01,  1.7627e-01, -2.2309e-01, -3.2777e-02,\n",
            "         -1.2488e-01,  8.0900e-04,  5.1665e-01,  7.6357e-02, -2.6891e-01,\n",
            "         -4.1425e-01, -6.1945e-01,  1.1874e-01,  4.0085e-01, -1.3576e-01,\n",
            "         -2.1783e-01,  1.8798e-01,  5.5665e-01,  3.4890e-01,  5.4712e-01,\n",
            "         -5.6161e-02,  3.5188e-01, -1.1164e-01, -5.1499e-01, -3.8676e-01,\n",
            "          3.6905e-01, -1.1481e-01, -8.8667e-02, -3.1647e-01,  2.4878e-01,\n",
            "         -2.8224e-01,  4.6145e-01, -3.5849e-02, -1.2159e-02, -4.3359e-02,\n",
            "          5.9261e-02, -1.8797e-01,  2.0475e-01, -1.8730e-01, -7.0400e-02,\n",
            "         -8.9920e-02,  1.4697e-01, -7.6497e-02, -4.9316e-02,  1.6795e-01,\n",
            "         -2.8238e-01, -4.6051e-02, -3.9185e-01,  7.6566e-02,  2.8557e-01,\n",
            "          2.8223e-01, -3.4453e-01,  1.9801e-01,  2.8901e-02,  7.1621e-01,\n",
            "          1.7012e-01,  2.7039e-01, -2.6950e-01, -4.1142e-02,  1.2418e-01,\n",
            "         -9.0965e-02, -1.8668e-01,  5.7593e-02, -4.0899e-01,  7.7774e-02,\n",
            "          7.2752e-01,  3.0295e-01, -8.5852e-01,  3.0329e-02,  1.6720e-01,\n",
            "         -2.1157e-01,  5.7569e-01,  3.3149e-01, -1.4067e-01, -2.1984e-01,\n",
            "          6.1255e-01,  1.8383e-01, -2.8501e-01,  7.4391e-01, -3.9152e-01,\n",
            "         -2.8624e-01,  1.9339e-01,  5.4817e-01, -1.2977e-01,  3.3915e-01,\n",
            "          9.0672e-02,  1.4349e-01,  3.3664e-02, -8.2577e-02,  3.6968e-01,\n",
            "          1.3206e-01,  1.7729e-01, -2.6445e-01,  7.0344e-01, -4.3248e-02,\n",
            "         -5.2685e-01,  5.2439e-01, -1.3083e-01,  8.1550e-02,  4.1677e-02,\n",
            "          8.2723e-02,  6.1366e-03,  6.9066e-01,  4.5727e-01,  3.5937e-01,\n",
            "         -2.6014e-02,  1.4916e-01,  2.7116e-01, -7.4094e-02,  4.4973e-01,\n",
            "          5.5116e-01,  5.5339e-02,  5.2643e-01,  4.3358e-01,  1.5713e-01,\n",
            "          7.4622e-01, -5.0163e-01, -3.0031e-01,  2.1830e-01,  4.3450e-01,\n",
            "          1.0398e-01, -1.0258e-01, -7.2554e-02, -2.6266e-01,  6.1490e-01,\n",
            "          7.2569e-04, -1.8856e-02,  1.1039e-01,  3.7501e-02, -1.4008e-01,\n",
            "         -2.4250e-01, -2.0325e-01, -9.5700e-02,  7.0813e-02,  2.3678e-01,\n",
            "         -2.1146e-01, -4.7236e-01, -4.4890e-01, -4.4688e-01,  1.6849e-01,\n",
            "         -1.4921e-01,  1.1849e-01, -2.8081e-01, -5.2466e-02, -4.8271e-02,\n",
            "          6.1052e-01, -1.9385e-01,  4.5753e-01, -1.8954e-01, -2.4816e-01,\n",
            "          6.7599e-01,  5.6938e-01, -2.6480e-01,  5.8279e-01, -2.8349e-01,\n",
            "         -2.0474e-01,  1.3826e-01, -2.1075e-01,  5.7913e-04,  2.3132e-01,\n",
            "          2.5676e-01, -2.0551e-01, -3.7780e-01,  4.3070e-01,  5.3402e-01,\n",
            "         -6.5612e-01, -3.5064e-01, -1.5863e-01,  3.7416e-01,  1.2142e-02,\n",
            "         -7.9099e-03, -3.4629e-01,  3.6320e-02, -7.2869e-01, -6.4224e-02,\n",
            "          7.7576e-01,  1.9219e-01, -2.5510e-01,  1.0314e-01,  3.3559e-01,\n",
            "         -3.5113e-01, -2.9117e-02, -2.4186e-01,  2.9348e-01,  4.1673e-01,\n",
            "          1.1777e-01,  4.2048e-01,  2.0607e-01, -6.4920e-02, -3.8076e-01,\n",
            "          1.4093e-01,  3.4834e-02, -2.5889e-01, -2.6586e-01, -1.0734e-02,\n",
            "          1.8793e-01,  1.8813e-01, -6.7367e-01,  2.3729e-01, -3.2475e-01,\n",
            "         -7.2850e-01, -2.4932e-01, -5.9717e-01,  1.1036e-01, -1.2062e-01,\n",
            "         -8.4251e-03, -3.7934e-01, -2.5480e-01,  4.7346e-01,  3.6209e-01,\n",
            "         -3.0348e-01, -4.8558e-01,  2.0857e-01]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertTokenizer\n",
        "sampled_data = \"\"\n",
        "\n",
        "# Function to get BERT embeddings for a given string\n",
        "def get_bert_embeddings(text):\n",
        "    # Load pre-trained BERT model and tokenizer\n",
        "    model_name = 'bert-base-uncased'\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize the input text and convert it into input IDs and attention mask\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Get the model outputs (embeddings)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # The embeddings for each token (we will take the last hidden state)\n",
        "    embeddings = outputs.last_hidden_state  # Shape: [batch_size, sequence_length, hidden_size]\n",
        "\n",
        "    # To get a single embedding for the entire sentence, you can take the average of the token embeddings\n",
        "    sentence_embedding = torch.mean(embeddings, dim=1)\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "# Example usage\n",
        "text = str(\"BERT is a powerful model for NLP tasks.\")\n",
        "embeddings = get_bert_embeddings(text)\n",
        "\n",
        "print(f\"Embedding: {embeddings}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OcA5UcZ_AMef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}