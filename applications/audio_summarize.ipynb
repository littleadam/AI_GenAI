{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJKUsVEYJDyH",
        "outputId": "555b1543-54bf-49aa-c30f-18462a632ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.17)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.18)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.11.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfu-vdKIWWk5",
        "outputId": "21b68361-1f30-479e-c43c-8c2d51badd58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide your OPENAI Keysk-IXIziutND7WHAjQp7FkwT3BlbkFJMoNhfIYINTbsJiuZyP9q\n",
            "Audio Converted to Text: Generative AI is a type of artificial intelligence technology that can produce various types of content, including text, imagery, audio, and synthetic data. The recent buzz around generative AI has been driven by the simplicity of new user interfaces for creating high-quality text, graphics, and videos in a matter of seconds. The technology, it should be noted, is not brand new. Generative AI was introduced in the 1960s in chatbots. But it was not until 2014, with the introduction of Generative Adversarial Networks, or GANs a type of machine learning algorithm that generative AI could create convincingly authentic images, videos, and audio of real people. On the one hand, this newfound capability has opened up opportunities that include better movie dubbing and rich educational content. It also unlocked concerns about deepfakes, digitally forged images or videos, and harmful cybersecurity attacks on businesses, including nefarious requests that realistically mimic an employee's boss. Two additional recent advances that will be discussed in more detail below have played a critical part in generative AI going mainstream, transformers and the breakthrough language models they enabled. Transformers are a type of machine learning that made it possible for researchers to train ever-larger models without having to label all of the data in advance. New models could thus be trained on billions of pages of text, resulting in answers with more depth. In addition, transformers unlocked a new notion called attention that enabled models to track the connections between words across pages, chapters, and books rather than just in individual sentences. And not just words, transformers could also use their ability to track connections to analyze code, proteins, chemicals, and DNA.\n",
            "Summary :Generative AI is an AI technology that can create various types of content. It has gained attention recently due to user-friendly interfaces that allow for quick creation of high-quality text, graphics, and videos. While generative AI has been around since the 1960s, it wasn't until 2014 with the introduction of Generative Adversarial Networks (GANs) that it could create realistic images, videos, and audio. This has led to both positive applications, such as improved movie dubbing and educational content, as well as concerns about deepfakes and cybersecurity attacks. Recent advances in transformers and language models have also played a significant role in making generative AI more mainstream, allowing for larger models to be trained and enabling analysis of connections between words, code, proteins, chemicals, and DNA.\n",
            "Query on Data:Provide details of AI\n",
            "Output:  There are many types of artificial intelligence technology, including generative AI which can produce various types of content such as text, imagery, audio, and synthetic data. Generative AI has been around since the 1960s but recent advances in technology have allowed for more realistic and convincing results, leading to both opportunities and concerns. Two key advances that have helped generative AI become more mainstream are transformers and language models.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain import OpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import openai\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import os\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def audio2Text(fileName,api_key):\n",
        "\n",
        "    audio_file = open(fileName,\"rb\")\n",
        "    client = openai.OpenAI(api_key=api_key)\n",
        "    transcript = client.audio.transcriptions.create(\n",
        "    model=\"whisper-1\",\n",
        "    file=audio_file,\n",
        "    response_format=\"text\"\n",
        "    )\n",
        "    #print(transcript)\n",
        "    return transcript\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to answer question\n",
        "def answer_question(documents,query):\n",
        "    # \"\"\"\n",
        "    # It performs question answering by using the document search object to find the most similar documents to the input query,\n",
        "    # and then passes the documents to the question answering chain with the input query as the question.\n",
        "    # The answer to the question is returned as output.\n",
        "    # \"\"\"\n",
        "\n",
        "    chain = load_qa_chain(llm=OpenAI(), chain_type=\"map_reduce\")\n",
        "    #query = \"what is the total number of AI publications?\"\n",
        "    txt = chain.run(input_documents=documents, question=query)\n",
        "    return txt\n",
        "\n",
        "# Convert Audio to Text\n",
        "def processUploadedFile(uploaded_file,api_key):\n",
        "    if uploaded_file is not None:\n",
        "\n",
        "        text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "      )\n",
        "    raw_text = audio2Text(uploaded_file,api_key)\n",
        "    texts = text_splitter.split_text(raw_text)\n",
        "    return texts\n",
        "\n",
        "# Summarize the provided Audio\n",
        "def summarize_response(llm,docs):\n",
        "    # Define prompt\n",
        "    prompt_template = \"\"\"Write a concise summary of the following:\n",
        "    \"{text}\"\n",
        "    CONCISE SUMMARY:\"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    # Define LLM chain\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
        "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "    # Define StuffDocumentsChain\n",
        "    stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
        "\n",
        "\n",
        "    return stuff_chain.run(docs)\n",
        "    # Text summarization\n",
        "    #chain = load_summarize_chain(llm, chain_type='map_reduce')\n",
        "    #return chain.run(docs)\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "\n",
        "\n",
        "\n",
        "    api_key = input(\"Provide your OPENAI Key : \")\n",
        "\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "    #wrapper = TextWrapper()\n",
        "\n",
        "    # Upload mp3 file\n",
        "\n",
        "    uploaded_file = '/content/sample_data/sample1.wav'\n",
        "    convertedtext = ''\n",
        "    convertedtext = processUploadedFile(uploaded_file,api_key)\n",
        "    print(\"Audio Converted to Text: \"+convertedtext[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    # Instantiate the LLM model\n",
        "    llm = OpenAI(temperature=0, openai_api_key=api_key)\n",
        "    # Split text\n",
        "\n",
        "    text_splitter = CharacterTextSplitter()\n",
        "    texts = text_splitter.split_text(convertedtext[0])\n",
        "    # Create multiple documents\n",
        "\n",
        "    docs = [Document(page_content=t) for t in texts]\n",
        "\n",
        "    summarize_txt = summarize_response(llm,docs)\n",
        "    print(\"Summary :\" +summarize_txt)\n",
        "\n",
        "    query = input(\"Query on Data:\")\n",
        "    txt = answer_question(docs,query)\n",
        "    print('Output:', txt)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}